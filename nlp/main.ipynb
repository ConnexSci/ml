{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 47788: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import os\n",
    "import sys\n",
    "\n",
    "# from torch_geometric.data import Data, DataLoader\n",
    "# from torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool\n",
    "# from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "### DATASET 1: NEED ANNOTATIONS TO WORK (21.6GB), SKIP FOR NOW\n",
    "ROOT = str(os.getcwd()).replace('/nlp', '/data/datasets/')\n",
    "DATA = ROOT + os.listdir(ROOT)[0]\n",
    "db_idx = {}\n",
    "\n",
    "for i in os.listdir(DATA):\n",
    "    db_idx[i] = []\n",
    "    for j, x in enumerate(os.listdir(DATA + '/' + i)):\n",
    "        db_idx[i].append(DATA + '/' + i + '/' + x)\n",
    "\n",
    "all_db = list(db_idx.keys())\n",
    "\n",
    "eg_db = pd.read_csv(db_idx[all_db[0]][0], sep='\\t', engine='python', error_bad_lines=False)\n",
    "eg_db.head()\n",
    "\n",
    "label_keys = {'O': None, 'B': 'Beginning', 'I': 'Intermediate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset ncbi_disease (/Users/devpatelio/.cache/huggingface/datasets/ncbi_disease/ncbi_disease/1.0.0/92314c7992b0b8a5ea2ad101be33f365b684a2cc011e0ffa29c691e6d32b2d03)\n",
      "100%|██████████| 3/3 [00:00<00:00, 106.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Identification, of, APC2, ,, a, homologue, of...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[The, adenomatous, polyposis, coli, (, APC, ),...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Complex, formation, induces, the, rapid, degr...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[In, colon, carcinoma, cells, ,, loss, of, APC...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Here, ,, we, report, the, identification, and...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                             tokens  \\\n",
       "0  0  [Identification, of, APC2, ,, a, homologue, of...   \n",
       "1  1  [The, adenomatous, polyposis, coli, (, APC, ),...   \n",
       "2  2  [Complex, formation, induces, the, rapid, degr...   \n",
       "3  3  [In, colon, carcinoma, cells, ,, loss, of, APC...   \n",
       "4  4  [Here, ,, we, report, the, identification, and...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0         [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0]  \n",
       "1  [0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2                        [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##NCBI Dataset --> Medical Subject Headings OR Online Mendelian Inheritance in Man\n",
    "### https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/\n",
    "from tabnanny import verbose\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('ncbi_disease')\n",
    "df_ncbi = pd.DataFrame(dataset['train'])\n",
    "\n",
    "df_ncbi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polyposis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 11.5kB/s]\n",
      "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 1.56MB/s]\n",
      "Downloading: 100%|██████████| 436k/436k [00:00<00:00, 3.08MB/s]\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 216kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "check_type = df_ncbi.iloc[0]['ner_tags'].index(2)\n",
    "print(df_ncbi.iloc[0]['tokens'][check_type]) #Check Keys\n",
    "\n",
    "max_length = max([len(x) for x in df_ncbi['tokens']])\n",
    "\n",
    "eg_sample = df_ncbi.iloc[0]['tokens']\n",
    "label_keys = {0: None, 1: 'mesh', 2: 'omim'}\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "text_tokenized = tokenizer(eg_sample, padding='max_length', max_length=max_length, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   146, 11951,  ...,     0,     0,     0],\n",
      "        [  101,  1104,   102,  ...,     0,     0,     0],\n",
      "        [  101, 10997,  1658,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   189, 27226,  ...,     0,     0,     0],\n",
      "        [  101, 17203,  1766,  ...,     0,     0,     0],\n",
      "        [  101,   119,   102,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(text_tokenized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "577ea14e5a220a2e2ceb4e7a6eabde6a6424f50ee02cc5f86f913307280e145a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
